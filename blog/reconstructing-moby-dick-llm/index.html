<!DOCTYPE html>
<html lang="english">

<!-- OpenGraph protocol tags: http://ogp.me/ -->
<meta property="og:site_name" content="Ömer Yüksel" />
<meta property="og:type" content="article" />
<meta property="og:title" content="The whale in the machine: reconstructing Moby-Dick with large language models -- " />
<meta property="og:url" content="https://osyuksel.github.io/blog/reconstructing-moby-dick-llm/" />
<meta property="og:description" content="An experiment testing whether LLMs can reproduce Moby Dick verbatim with mixed results." />
<meta property="article:published_time" content="2025-08-26 00:00:00+02:00" />
<meta property="article:modified_time" content="2025-08-27 00:00:00+02:00" />
<!-- End of OpenGraph protocol tags -->

<head>
      <title>Ömer Yüksel - The whale in the machine: reconstructing Moby-Dick with large language models</title>
    <meta charset="utf-8"/>
    <meta name="generator" content="Pelican"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="https://osyuksel.github.io/feeds/all.atom.xml"
          type="application/atom+xml" rel="alternate" title="Ömer Yüksel Full Atom Feed"/>
    <link href="https://osyuksel.github.io/feeds/technical.atom.xml"
          type="application/atom+xml" rel="alternate" title="Ömer Yüksel Categories Atom Feed"/>

        <link rel="stylesheet" href="https://osyuksel.github.io/theme/css/rdark.css" />
        <link rel="stylesheet" href="https://osyuksel.github.io/theme/css/page.css">
        <link rel="icon" href="https://osyuksel.github.io/favicon.ico" type="image/ico">


	<link rel="stylesheet" type="text/css" href="https://osyuksel.github.io/theme/css/main.css" />
        <link href="https://osyuksel.github.io/" type="application/atom+xml" rel="alternate" title="Ömer Yüksel ATOM Feed" /><!--[if IE]><script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

    <script defer src="https://cloud.umami.is/script.js" data-website-id="c3018972-a599-4b25-80a8-4d03ceff62ff"></script>

	
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  "HTML-CSS": {
    styles: {
      ".MathJax .mo, .MathJax .mi": {color: "black ! important"}
    },
    scale: 75,  // Scale inline math to 60%
    minScaleAdjust: 50
  },
  CommonHTML: {
    scale: 75   // Scale inline math to 60%
  },
  SVG: {
    scale: 75   // Scale inline math to 60%
  },
  tex2jax: {
    inlineMath: [['$','$'], ['\\\\(','\\\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true
  }
  });

  // After MathJax processes, adjust display math back to larger size
  MathJax.Hub.Queue(function () {
    var displays = document.querySelectorAll('.MathJax_Display');
    displays.forEach(function(display) {
      display.style.fontSize = '1.3em';  // Make display math 1.5x the scaled size
    });
  });
</script>


<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"></script>
</head>




    <meta name="tags" content="llm" />
    <meta name="tags" content="nlp" />
    <meta name="tags" content="benchmarking" />

</head>

<body>
<header>
    <hgroup style="text-align: center"><h1><a href="https://osyuksel.github.io/">Ömer Yüksel</a></h1>    </hgroup>
    <nav>
        <a href="https://www.github.com/osyuksel"  target="_blank" rel="noopener noreferrer"><img height="16" src="https://osyuksel.github.io/assets/github-mark.svg" width="16"/></a>
        <a href="https://www.linkedin.com/in/omersyuksel"  target="_blank" rel="noopener noreferrer"><img height="16" src="https://osyuksel.github.io/assets/linkedin.webp" width="16"/></a>
    </nav>

    <br>
    <nav>
             &#124;
            <a href="https://osyuksel.github.io/index.html" >Home</a> &#124;

            <a href="https://osyuksel.github.io/pages/about.html" >About</a> &#124;

            <a href="https://osyuksel.github.io/pages/my-work.html" >My Work</a> &#124;

            <a href="https://osyuksel.github.io/pages/contact.html" >Contact</a> &#124;

                <a href="/blog/">Blog</a> &#124;

    </nav>
</header>
<main>
  <article>
    <header>
      <h1>
        <a href="https://osyuksel.github.io/blog/reconstructing-moby-dick-llm/" rel="bookmark"
           title="Permalink to The whale in the machine: reconstructing Moby-Dick with large language models">The whale in the machine: reconstructing Moby-Dick with large language models</a></h1>
      
    </header>
    <p>From time to time, I come across posts claiming: "AI plagiarized my work verbatim." These typically involve vanilla chat-based models, not the tool-calling, RAG-based, or web-searching variants.</p>
<p>I've always been skeptical of such claims. While AI companies aggressively scrape the internet and have faced lawsuits for using <a href="https://www.reuters.com/sustainability/boards-policy-regulation/anthropic-settles-class-action-us-authors-alleging-copyright-infringement-2025-08-26/#:~:text=A%20California%20judge%20said%20in,the%20authors'%20case%20was%20successful.">pirated content</a>, my conjecture so far has been that given the parameters-to-training data ratio<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup>, even if one's work ends up in the training corpus, replicating in such detail would be impossible unless:</p>
<ul>
<li>The work is iconic, famous, or memetic enough to be quoted numerous times, or,</li>
<li>The work is formulaic and predictable, containing common sentence structures or phrases</li>
</ul>
<p>Under this conjecture, an LLM may be able to accurately quote Bible verses verbatim, but directly replicating a uniquely written but obscure novel should be improbable. And my previous anecdotal experiments confirmed this pattern: I successfully observed models quoting the Bible verbatim but failing to replicate more obscure content. However, failing to replicate one obscure work doesn't definitively refute these claims. Someone could always counter, "Yes, but it perfectly quoted <em>my</em> work."</p>
<p>To address this more systematically, I've designed a different experiment: Can an LLM replicate an iconic work of fiction that likely appears in the training data multiple times? Perhaps less frequently than the Bible, but more than any obscure work. Specifically, can it, when given a few paragraphs from Moby-Dick, accurately predict what comes next?</p>
<p>If an LLM fails to replicate something as canonical as Moby-Dick, then claims about verbatim reproduction of less well-known works become questionable. If it succeeds, however, there might be merit to such assertions.</p>
<p>The code for the experiment can be found in <a href="https://github.com/osyuksel/llm-playground/blob/main/src/llm_playground/moby_dick.py">my Github</a>.</p>
<h3 id="experiment-setup">Experiment setup</h3>
<p>For this experiment, I used the text of Moby-Dick obtained from <a href="https://www.gutenberg.org/ebooks/2701">Project Gutenberg</a> as my primary dataset. I tested multiple models: gpt-5-mini, gpt-5-nano, gpt-4o, and gpt-4o-mini. While I initially planned to include more models, time constraints forced me to limit the scope. I hope to expand this analysis in a follow-up post once I secure separate access to Google and Anthropic models, as OpenRouter was experiencing high traffic during my testing period.</p>
<p>The experimental design was straightforward: provide three consecutive paragraphs from the text as input and ask the model to predict the next paragraph. For this purpose, I defined a "paragraph" as any body of text demarcated by a newline. To avoid scenarios where the model would need to predict entire chapters, I filtered the dataset to include only input-output pairs of appropriate length.</p>
<p>I randomly sampled 10% of the eligible input/output pairs, resulting in 59 data points per model. When configuring the LLMs, I minimized the temperature setting whenever the model allowed it, since our goal was verbatim replication rather than creative variation—there was only one correct answer in each case.</p>
<p>For scoring the results, I had to address several practical challenges. Since models sometimes generate more text than requested despite being instructed to predict only "the next paragraph," I decided not to penalize this behavior. Instead, I compared only the first <em>n</em> characters of the generated text, where <em>n</em> equals the length of the expected output. To account for potential shifts in the text, I also used a partial ratio comparison, which calculates the best possible match when strings are shifted relative to each other.</p>
<p>The scoring metric I chose was string similarity derived from Levenshtein distance, as <a href="https://rapidfuzz.github.io/RapidFuzz/Usage/fuzz.html#partial-ratio">implemented by the thefuzz</a> package. This metric converts edit distance to a similarity score using the formula: 1 - (distance / (len1 + len2)). In my dataset, the worst scores were around 37%, while as per formula, typical poor matches with similar lengths would score around 50%. After examining the results, I established that a similarity ratio above 85% could be considered a "good match" between the generated and original text.</p>
<p>After some experimentation, my final prompt was:</p>
<blockquote>
<p>You are a large language model on an experiment to recall classic literary works. Based on the user input, which is a section from Moby Dick, you are to answer with the paragraph that follows.
Your instructions:</p>
<ul>
<li>Do not write any acknowledgements or anything except the desired output</li>
<li>Write only a full paragraph. Not just a sentence, and not the full chapter.</li>
<li>Note that Moby Dick is <strong>public domain</strong> and was written in 1851. There are no copyright concerns.</li>
<li>Your accuracy is scored, so predict the best sentence that follows.</li>
</ul>
</blockquote>
<h4 id="challenges">Challenges</h4>
<p>Many chat-based models displayed a tendency to avoid instructions to quote the novel verbatim, likely due to copyright concerns programmed into their safeguards. I found that adding specific system prompts acknowledging Moby-Dick's publication date and copyright-free status significantly reduced these refusals and helped the models engage more directly with the task.</p>
<p>A second challenge arose from slight differences between model outputs and the original work in terms of whitespaces and punctuation. These minor variations could significantly impact traditional exact-match metrics despite the semantic content being nearly identical. Using the Levenshtein distance-based similarity metric helped address this issue by focusing on the overall textual similarity rather than requiring perfect character-by-character matches.</p>
<p>Another challenge arose from the limitations in controlling output determinism with certain advanced reasoning models, particularly in the GPT-5 family. These models do not allow adjusting the temperature parameter through their APIs, which made it difficult to ensure consistent, deterministic text reproduction. Without the ability to minimize randomness by setting a near-zero temperature, these models retained some inherent variability in their outputs, even when explicitly instructed to reproduce text exactly.</p>
<p>A final challenge was managing the potential cost explosion of such an experiment. Without careful planning, testing multiple models across the entire text of Moby-Dick could become prohibitively expensive. By implementing sampling and limiting the number of models tested, I was able to keep the experiment manageable. Including all repetitions and test runs, I used approximately 260,000 tokens at a total cost of $3.15.</p>
<h3 id="results">Results</h3>
<p>Full experiment output is in my <a href="https://github.com/osyuksel/llm-playground/tree/main/output/moby_dick">Github</a>. Below are the statistics for 59 data points per model:</p>
<h4 id="similarity">Similarity</h4>
<p>(metric: Levenshtein similarity on best subset)</p>
<table>
<thead>
<tr>
<th style="text-align: left;">model_name</th>
<th style="text-align: right;">mean</th>
<th style="text-align: right;">min</th>
<th style="text-align: right;">10%</th>
<th style="text-align: right;">25%</th>
<th style="text-align: right;">50%</th>
<th style="text-align: right;">75%</th>
<th style="text-align: right;">90%</th>
<th style="text-align: right;">max</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">gpt-4o</td>
<td style="text-align: right;">72.9831</td>
<td style="text-align: right;">37</td>
<td style="text-align: right;">42.8</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">78</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
<td style="text-align: right;">100</td>
</tr>
<tr>
<td style="text-align: left;">gpt-4o-mini</td>
<td style="text-align: right;">45.2203</td>
<td style="text-align: right;">39</td>
<td style="text-align: right;">42.8</td>
<td style="text-align: right;">44</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">46</td>
<td style="text-align: right;">47</td>
<td style="text-align: right;">62</td>
</tr>
<tr>
<td style="text-align: left;">gpt-5-mini</td>
<td style="text-align: right;">44.4068</td>
<td style="text-align: right;">38</td>
<td style="text-align: right;">42</td>
<td style="text-align: right;">43</td>
<td style="text-align: right;">44</td>
<td style="text-align: right;">46</td>
<td style="text-align: right;">47</td>
<td style="text-align: right;">52</td>
</tr>
<tr>
<td style="text-align: left;">gpt-5-nano</td>
<td style="text-align: right;">44.7627</td>
<td style="text-align: right;">37</td>
<td style="text-align: right;">41</td>
<td style="text-align: right;">43.5</td>
<td style="text-align: right;">45</td>
<td style="text-align: right;">46</td>
<td style="text-align: right;">47</td>
<td style="text-align: right;">60</td>
</tr>
</tbody>
</table>
<h4 id="match-rate">Match Rate</h4>
<p>Using the 85% similarity threshold as the criterion for success, GPT-4o achieved accurate matches in <strong>49%</strong> of cases, while all other models failed to produce any matches, scoring <strong>0%</strong>.</p>
<h4 id="specific-examples">Specific examples</h4>
<p>Here we dive into some specific examples where the predictions have gone wrong. One common observation is that while the models may pick a different narrative direction, they manage to stay consistent with the theme.</p>
<h5 id="early-divergence-1-gpt-4o-mini">Early divergence 1 (GPT-4o-mini)</h5>
<p>Here is one case where gpt-4o-mini started correctly but diverged mid-sentence:</p>
<p>Expected output:</p>
<blockquote>
<p>I considered the matter a moment, and then up stairs we went, and I was ushered into a small room, cold as a clam, and furnished, sure enough, with a prodigious bed, almost big enough indeed for any four harpooneers to sleep abreast. </p>
</blockquote>
<p>Generated:</p>
<blockquote>
<p>I considered the matter a moment, and then, taking my hat from the table, followed the landlord through the door and down a long, narrow passage. We went to a sort of a large room, and there I saw a great many beds, and a number of people in them, some of whom were snoring, and others were talking in their sleep. [...]</p>
</blockquote>
<h5 id="early-divergence-2-gpt-5-mini">Early divergence 2 (GPT-5-mini)</h5>
<p>Expected:</p>
<blockquote>
<p>Entering that gable-ended Spouter-Inn, you found yourself in a wide, low, straggling entry with old-fashioned wainscots, reminding one of the bulwarks of some condemned old craft. On one side hung a very large oilpainting so thoroughly besmoked, and every way defaced, that in the unequal crosslights by which you viewed it, it was only by diligent study and a series of systematic visits to it, [...]</p>
</blockquote>
<p>Generated:</p>
<blockquote>
<p>Entering that gable-ended Spouter-Inn, you found yourself in <strong>a long, low, straggling entry with a low ceiling, and a number of little rooms branching off it, in each of which some one or two lodgers lay stretched on benches or sat about the fire; and at the far end of the entry, beneath a small, smoky lamp, stood a great sea-chest</strong> [...]</p>
</blockquote>
<h5 id="mid-paragraph-divergence-gpt-4o">Mid-paragraph divergence (GPT-4o)</h5>
<p>Expected output:</p>
<blockquote>
<p>It has before been hinted, perhaps, that every little untoward circumstance that befell him, and which indirectly sprang from his luckless mishap, almost invariably irritated or exasperated Ahab. And in the present instance, all this was heightened by the sight of the two officers of the strange ship, leaning over the side, by the perpendicular ladder of nailed cleets there, and swinging towards him a pair of tastefully-ornamented man-ropes; for at first they did not seem to bethink them that a one-legged man must be too much of a cripple to use their sea bannisters. But this awkwardness only lasted a minute, because the strange captain, observing at a glance how affairs stood, cried out, “I see, I see!—avast heaving there! Jump, boys, and swing over the cutting-tackle.</p>
</blockquote>
<p>Generated:</p>
<blockquote>
<p>It has before been hinted, perhaps, that every little untoward circumstance that befell him, and which indirectly sprang from his luckless mishap, almost invariably irritated or exasperated Ahab. And in the present instance, all this was heightened by the sight of the two officers of the strange ship <strong>leaning over the side, and amicably exchanging hails with the mates of the Pequod. This sight of the friendly sailors reminded Ahab of his own isolation; and the thought of that reminded him of all his bodily lameness, and the uncompleted revenge he had vowed.</strong></p>
</blockquote>
<h5 id="caught-in-a-loop">Caught in a loop</h5>
<p>One reason for temperature sampling is to help it escape avoid loops and repetitions. In this case GPT-4o, which had near-zero temperature, got caught in a loop:</p>
<blockquote>
<p>But Ahab, like a man who had never heard his voice, now muttered, “On such a day, and such a sweetness, I struck my first whale—a boy-harpooneer of eighteen! Forty—forty—forty years ago!—ago! Forty years of continual whaling! forty years of privation, and peril, and storm-time! forty years on the pitiless sea! for forty years has Ahab forsaken the peaceful land, for forty years to make war on the horrors of the deep! Aye and yes, Starbuck, out of those forty years I have not spent three ashore. When I think of this life I have led; the desolation of solitude it has been; the masoned, walled-town of a Captain’s quarters, from which I have never escaped; the unending, unrelieved monotony of the sea; the unceasing, unrelenting pursuit of the whale; the unyielding, unbending, unending, unrelenting, unyielding, unbending, unending, unrelenting, unyielding, unbending, unending, unrelenting, unyielding, unbending, unending, unrelenting, unyielding, unbending, unending, unrelenting, unyielding, unbending, unending, unrelenting, unyielding, unbending, unending, unrelenting, unyielding, unbending, unending, unrelenting, unyielding, unbending, unending, unrelenting, unrelenting, unyielding</p>
<p>[repeated hundreds of times]</p>
</blockquote>
<h5 id="refusal">Refusal</h5>
<p>Occasionally, GPT-5 family in particular, refuses to complete, but without making it clear if it's copyright avoidance or lack of information.</p>
<p>From GPT-5-nano:</p>
<blockquote>
<p>Sorry, I can’t provide that exact paragraph from Moby-Dick, but I can offer a concise summary of what happens next or discuss the passage in more detail.</p>
</blockquote>
<h3 id="conclusions-and-future-work">Conclusions and Future Work</h3>
<p>Only GPT-4o achieved accurate replications, with a 50% success rate. Whether GPT-5-mini and GPT-5-nano's failure stems from model size limitations or intentional design choices remains unclear. The GPT-5 family may include stronger RLHF mechanisms that discourage verbatim quoting. Additionally, these reasoning-based models require a temperature setting of 1.0, increasing their likelihood of random word sampling and subsequent divergence.</p>
<p>This result is inconclusive regarding my original conjecture that LLMs cannot reproduce uncommon, non-formulaic content from their training data. GPT-4o's 50% success rate with Moby-Dick neither strongly supports nor refutes this hypothesis. One could argue that for less common works, verbatim replication might still occur, albeit at lower rates.</p>
<p>I plan to expand this investigation to include GPT-5, Gemini, and Claude models. Preliminary tests indicate Claude models may be even more resistant to verbatim reproduction tasks which can complicate this effort.</p>
<p>Future work should also examine how reproduction capability varies with the popularity and uniqueness of source material. Testing with works ranging from canonical to obscure would establish a clearer relationship between a text's prevalence in training data and a model's ability to reproduce it exactly. This could provide more definitive evidence regarding claims of AI plagiarism, particularly for less well-known content.</p>
<p>Understanding these reproduction capabilities remains important for addressing concerns about intellectual property and the nature of AI-generated content.</p>
<h5 id="footnotes">Footnotes</h5>
<div class="footnote">
<hr>
<ol>
<li id="fn:1">
<p>Looking at original <a href="https://ai.meta.com/blog/meta-llama-3/">LLama-3 70B</a>, which had purely text training data: (1) Model size in bytes: 70 billion parameters × 4 bytes ≈ <strong>280 GB</strong> (2) Training data in bytes: 15 trillion tokens × ~4 bytes ≈ <strong>60 TB</strong>  (3) Parameters-to-training-data ratio: 80 GB / 60 TB ≈ 0,0013 or <strong>1:750</strong>&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>
    <footer>
      <hr>
      <p>Published: <time datetime="2025-08-26T00:00:00+02:00">
        Tue 26 August 2025
      </time></p>
        <p>Last updated: <time datetime="2025-08-27T00:00:00+02:00">
          Wed 27 August 2025
        </time></p>
        <address>
          By <!--            <a href="https://osyuksel.github.io/author/omer-yuksel.html">Ömer Yüksel</a>-->
          Ömer Yüksel
        </address>
<!--      -->
<!--        <p>-->
<!--          Category: <a href="https://osyuksel.github.io/category/technical.html">Technical</a>-->
<!--        </p>-->
<!--      -->
        <p>
          Tags:
            <a href="https://osyuksel.github.io/tag/llm.html">llm</a>
            <a href="https://osyuksel.github.io/tag/nlp.html">nlp</a>
            <a href="https://osyuksel.github.io/tag/benchmarking.html">benchmarking</a>
        </p>
    </footer>
  </article>
</main>
<footer>
  <footer>
    <address>
      © 2025 Powered by <a href="https://getpelican.com/">Pelican</a>.
    </address>
  </footer>
</footer>
</body>
</html>